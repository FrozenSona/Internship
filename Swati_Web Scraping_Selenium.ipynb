{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\gavel\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\gavel\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the webdriver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "# driver=webdriver.Chrome(r\"C:\\Users\\gavel\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the driver\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/' \n",
    "driver.get(url)    #this will open naukari.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"d27a6db10678637386ff028f02c7e92a\", element=\"dfa037ea-7489-45d9-8894-d16f92749e62\")>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobsearch = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "jobsearch          #code for job search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsearch.send_keys(\"Data Analyst\") #entering data analyst into search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element_by_id('qsb-location-sugg')\n",
    "location.send_keys(\"Bangalore\")     #code for location search box and entering banglore into location search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_class_name('btn')\n",
    "search.click()   # clicking on click button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []   #creating empty lists for job title,company,location and experience\n",
    "company = []\n",
    "locations = []\n",
    "xp = []\n",
    "\n",
    "# extracting title,copany name,location and experience\n",
    "title_tag = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "xp_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using for loop to store all desired data into lists\n",
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "for c in company_tag:\n",
    "    company.append(c.text)\n",
    "company\n",
    "for l in location_tag:\n",
    "    locations.append(l.text)\n",
    "for x in xp_tag:\n",
    "    xp.append(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>4-5 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst (On Contract)</td>\n",
       "      <td>Rupeek Fintech Pvt Ltd</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jr . Data Analyst</td>\n",
       "      <td>Armorblox</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Analyst / Data Analyst</td>\n",
       "      <td>GetSimpl</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring Business Data Analyst +ETL- Tech Mahind...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Consultant - Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manager - Data Analyst</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title                 Company  \\\n",
       "1                                 Senior Data Analyst                Flipkart   \n",
       "2                          Data Analyst (On Contract)  Rupeek Fintech Pvt Ltd   \n",
       "3                                   Jr . Data Analyst               Armorblox   \n",
       "4                     Business Analyst / Data Analyst                GetSimpl   \n",
       "5   Hiring Business Data Analyst +ETL- Tech Mahind...           Tech Mahindra   \n",
       "6                                        Data Analyst  IBM India Pvt. Limited   \n",
       "7                           Consultant - Data Analyst                Flipkart   \n",
       "8                                        Data Analyst                Flipkart   \n",
       "9                                        Data Analyst                Flipkart   \n",
       "10                             Manager - Data Analyst                 Genpact   \n",
       "\n",
       "   Experience             Location  \n",
       "1     4-5 Yrs  Bengaluru/Bangalore  \n",
       "2     0-2 Yrs  Bangalore/Bengaluru  \n",
       "3     0-2 Yrs  Bangalore/Bengaluru  \n",
       "4     2-4 Yrs  Bangalore/Bengaluru  \n",
       "5    6-10 Yrs   (WFH during Covid)  \n",
       "6     1-4 Yrs  Bangalore/Bengaluru  \n",
       "7     1-3 Yrs  Bengaluru/Bangalore  \n",
       "8     1-2 Yrs  Bengaluru/Bangalore  \n",
       "9     1-3 Yrs  Bengaluru/Bangalore  \n",
       "10   5-10 Yrs  Bengaluru/Bangalore  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note:lots of pop window comes while performing this task for better result colse all pops manually\n",
    "\n",
    "# creating datframe\n",
    "JobDF = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Experience\":xp[0:10],\"Location\":locations[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1   #this will start your indexing with 1 not with 0\n",
    "\n",
    "JobDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")  #initiated web driver and opening naukari.com in chrome\n",
    "\n",
    "url = 'https://www.naukri.com/' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsearch = driver.find_element_by_id('qsb-keyword-sugg')  #code for job search box\n",
    "jobsearch\n",
    "\n",
    "jobsearch.send_keys(\"Data Scientist\")  #entering data scientist into job search box\n",
    "\n",
    "location = driver.find_element_by_id('qsb-location-sugg')  #code for location search box and entering banglore into this box\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "search = driver.find_element_by_class_name('btn')  #code for click button\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []  #creating empty lists for desired r3esult\n",
    "company = []\n",
    "locations = []\n",
    "\n",
    "#codes for job title,company name,and for locations\n",
    "title_tag = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span[1]\")\n",
    "\n",
    "# using loop to store all desired data into list\n",
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "# job_title\n",
    "for c in company_tag:\n",
    "    company.append(c.text)\n",
    "# company\n",
    "for l in location_tag:\n",
    "    locations.append(l.text)\n",
    "# locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cognitive/AI Senior Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Programmer - Data Scientist</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Juniper Networks</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead/Senior Data Scientist (NLP)</td>\n",
       "      <td>Samya.AI A FRACTAL Entity</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Ericsson Global Services</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist Analytics</td>\n",
       "      <td>ExecBoardinAsia</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Staff Data Scientist</td>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Becton Dickinson India Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jr. Data Analyst/ Jr. Data Scientist</td>\n",
       "      <td>Sejal Consulting Hub</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>Pune, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Job Title  \\\n",
       "1     Cognitive/AI Senior Data Scientist   \n",
       "2       Lead Programmer - Data Scientist   \n",
       "3                  Senior Data Scientist   \n",
       "4       Lead/Senior Data Scientist (NLP)   \n",
       "5                  Senior Data Scientist   \n",
       "6        Senior Data Scientist Analytics   \n",
       "7            Senior Staff Data Scientist   \n",
       "8                    Lead Data Scientist   \n",
       "9   Jr. Data Analyst/ Jr. Data Scientist   \n",
       "10                 Senior Data Scientist   \n",
       "\n",
       "                                    Company  \\\n",
       "1                    IBM India Pvt. Limited   \n",
       "2   GlaxoSmithKline Pharmaceuticals Limited   \n",
       "3                          Juniper Networks   \n",
       "4                 Samya.AI A FRACTAL Entity   \n",
       "5                  Ericsson Global Services   \n",
       "6                           ExecBoardinAsia   \n",
       "7                              Baker Hughes   \n",
       "8            Becton Dickinson India Pvt Ltd   \n",
       "9                      Sejal Consulting Hub   \n",
       "10                                    Wipro   \n",
       "\n",
       "                                             Location  \n",
       "1                                 Bengaluru/Bangalore  \n",
       "2                                 Bangalore/Bengaluru  \n",
       "3                                 Bangalore/Bengaluru  \n",
       "4                                 Bangalore/Bengaluru  \n",
       "5                                 Bangalore/Bengaluru  \n",
       "6                                 Bangalore/Bengaluru  \n",
       "7                                 Bangalore/Bengaluru  \n",
       "8                                 Bangalore/Bengaluru  \n",
       "9   Hyderabad/Secunderabad, Bangalore/Bengaluru, M...  \n",
       "10             Pune, Bangalore/Bengaluru, Delhi / NCR  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note:lots of pop window comes while performing this task for better result colse all pops manually\n",
    "\n",
    "#creating dataframe\n",
    "JobDF = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Location\":locations[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1\n",
    "\n",
    "JobDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for better result remove all pop's manually :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")   #initiated web driver and opening naukari.com in chrome \n",
    "\n",
    "url = 'https://www.naukri.com/' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsearch = driver.find_element_by_id('qsb-keyword-sugg')  #code for job search box\n",
    "jobsearch\n",
    "jobsearch.send_keys(\"Data Scientist\")  #entering data scientist into job search box\n",
    "search = driver.find_element_by_class_name('btn')#clicking with this code on click button\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying filters with below codes\n",
    "# code for location filter\n",
    "location_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/p/span[1]\")\n",
    "location_filter.click()\n",
    "\n",
    "# code for salary filter\n",
    "salary_filter = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/p/span[1]')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []  #creating empty lists for stroing job title,location,company name and experience\n",
    "company = []\n",
    "locations = []\n",
    "xp = []\n",
    "\n",
    "#scraping job title ,company name,location,experince with below codes\n",
    "title_tag = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "company_tag = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "location_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span[1]\")\n",
    "xp_tag = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "\n",
    "#applying loop to store desired data into empty list which we created earlier\n",
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "for c in company_tag:\n",
    "    company.append(c.text)\n",
    "# company\n",
    "for l in location_tag:\n",
    "    locations.append(l.text)\n",
    "for x in xp_tag:\n",
    "    xp.append(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Project Manager | Team Leader | Senior Data Sc...</td>\n",
       "      <td>Tidyquant (OPC) Private Limited</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist/ Senior Data Scientist</td>\n",
       "      <td>Newgen Software Technologies</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NTT DATA_ Hiring For BIG DATA ,DATA Scientist,...</td>\n",
       "      <td>NTT Data Business Solutions Pvt Ltd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Noida, Kolkata, Hyderabad/Secunderabad, Ahmeda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Teleperformance</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Analyst / Data Scientist</td>\n",
       "      <td>Careerera</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst / Data Scientist / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, Ghaziabad, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ApplyBoard</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Whizhack Technologies pvt ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>One Mobikwik Systems Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "1   Project Manager | Team Leader | Senior Data Sc...   \n",
       "2                           Hiring For Data Scientist   \n",
       "3               Data Scientist/ Senior Data Scientist   \n",
       "4   NTT DATA_ Hiring For BIG DATA ,DATA Scientist,...   \n",
       "5                                      Data Scientist   \n",
       "6            Hiring For Data Analyst / Data Scientist   \n",
       "7   Data Analyst / Data Scientist / Business Analy...   \n",
       "8                                      Data Scientist   \n",
       "9                                      Data Scientist   \n",
       "10                                     Data Scientist   \n",
       "\n",
       "                                 Company Experience  \\\n",
       "1        Tidyquant (OPC) Private Limited    1-5 Yrs   \n",
       "2         Tata Consultancy Services Ltd.    4-9 Yrs   \n",
       "3           Newgen Software Technologies    2-5 Yrs   \n",
       "4    NTT Data Business Solutions Pvt Ltd    3-8 Yrs   \n",
       "5                        Teleperformance    4-9 Yrs   \n",
       "6                              Careerera    1-3 Yrs   \n",
       "7              GABA Consultancy services    0-0 Yrs   \n",
       "8                             ApplyBoard    3-7 Yrs   \n",
       "9          Whizhack Technologies pvt ltd    2-5 Yrs   \n",
       "10  One Mobikwik Systems Private Limited    2-5 Yrs   \n",
       "\n",
       "                                             Location  \n",
       "1                                              Remote  \n",
       "2   Hyderabad/Secunderabad, Pune, Chennai, Bangalo...  \n",
       "3                                               Noida  \n",
       "4   Noida, Kolkata, Hyderabad/Secunderabad, Ahmeda...  \n",
       "5                           Gurgaon/Gurugram, Chennai  \n",
       "6                              Noida(Sector-59 Noida)  \n",
       "7                       Noida, Ghaziabad, Delhi / NCR  \n",
       "8                                    Gurgaon/Gurugram  \n",
       "9                                    Gurgaon/Gurugram  \n",
       "10                                   Gurgaon/Gurugram  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "JobDF = pd.DataFrame({\"Job Title\":job_title[0:10],\"Company\":company[0:10],\"Experience\":xp[0:10],\"Location\":locations[0:10]})\n",
    "JobDF.reset_index(drop=True,inplace = True)\n",
    "JobDF.index+= 1\n",
    "\n",
    "JobDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for better result please close all pops manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom of the page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.\n",
    "Note: That all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = 'https://www.flipkart.com' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "glassessearch = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "glassessearch.send_keys(\"Sunglasses\")\n",
    "search = driver.find_element_by_class_name('L0Z3Pu')\n",
    "search.click()\n",
    "\n",
    "#please close login page manually here\n",
    "\n",
    "# creating empty lits\n",
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "disc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping brand,price,discount,description\n",
    "brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "\n",
    "for b in brand_tag:\n",
    "    brand.append(b.text)\n",
    "for d in desc_tag :\n",
    "    desc.append(d.text)\n",
    "for p in price_tag:\n",
    "    price.append(p.text)\n",
    "for c in disc_tag:\n",
    "    disc.append(c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0   #code for next button and i<2 means next button will work till page 3 means where i will get 100 products\n",
    "nextbtn = driver.find_element_by_class_name('_1LKTO3')\n",
    "while(i<2):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    \n",
    "    for b in brand_tag:\n",
    "        try:\n",
    "            brand.append(b.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for d in desc_tag :\n",
    "        try:\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for p in price_tag:\n",
    "        try:\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            pass\n",
    "    for c in disc_tag:\n",
    "        try:\n",
    "            disc.append(c.text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    if 'inactive' in nextbtn.get_attribute('class'): \n",
    "        break;\n",
    "    \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹188</td>\n",
       "      <td>85% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹248</td>\n",
       "      <td>90% off</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "      <td>UV Protection Spectacle Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "      <td>UV Protection Round Sunglasses (50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹719</td>\n",
       "      <td>20% off</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>₹383</td>\n",
       "      <td>61% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>₹383</td>\n",
       "      <td>61% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹711</td>\n",
       "      <td>64% off</td>\n",
       "      <td>UV Protection Sports Sunglasses (73)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand Name Price(₹) Discount  \\\n",
       "1              SRPM     ₹188  85% off   \n",
       "2         Elligator     ₹248  90% off   \n",
       "3          Fastrack     ₹639  20% off   \n",
       "4    ROZZETTA CRAFT     ₹499  75% off   \n",
       "5            PIRASO     ₹200  87% off   \n",
       "..              ...      ...      ...   \n",
       "96        ROYAL SON     ₹664  66% off   \n",
       "97         Fastrack     ₹719  20% off   \n",
       "98        Rich Club     ₹383  61% off   \n",
       "99        Rich Club     ₹383  61% off   \n",
       "100       ROYAL SON     ₹711  64% off   \n",
       "\n",
       "                                          Description  \n",
       "1              UV Protection Wayfarer Sunglasses (56)  \n",
       "2                 UV Protection Round Sunglasses (54)  \n",
       "3    UV Protection Rectangular Sunglasses (Free Size)  \n",
       "4      UV Protection Spectacle Sunglasses (Free Size)  \n",
       "5               UV Protection Aviator Sunglasses (54)  \n",
       "..                                                ...  \n",
       "96                UV Protection Round Sunglasses (50)  \n",
       "97   Polarized, UV Protection Aviator Sunglasses (58)  \n",
       "98      UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "99      UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "100              UV Protection Sports Sunglasses (73)  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "SunglassesDF = pd.DataFrame({\"Brand Name\":brand[0:100],\"Price(₹)\":price[0:100],\"Discount\":disc[0:100],\"Description\":desc[0:100],})\n",
    "SunglassesDF.reset_index(drop=True,inplace = True)\n",
    "SunglassesDF.index+= 1\n",
    "SunglassesDF.shape\n",
    "SunglassesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.Scrape the data for first 100 reviews.\n",
    "#### 1. Rating\n",
    "#### 2. Review_summary\n",
    "#### 3. Full review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")  #initiating webdriver and flipkart webpage\n",
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewall = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[8]/div/div/div[5]/div/a/div/span')\n",
    "viewall.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_sum = []  #creating empty list\n",
    "rating = []\n",
    "rev = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_sum_tag = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "rating_tag = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "rev_tag = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    \n",
    "\n",
    "for r in rev_sum_tag:\n",
    "    rev_sum.append(r.text)\n",
    "for j in rating_tag :\n",
    "    rating.append(j.text)\n",
    "for k in rev_tag:\n",
    "    rev.append(k.text.replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0  #next button code\n",
    "nextbtn = driver.find_element_by_class_name('_1LKTO3')\n",
    "while(i<10):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    rev_sum_tag = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    rating_tag = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    rev_tag = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for r in rev_sum_tag:\n",
    "        try:\n",
    "            rev_sum.append(r.text)\n",
    "        except:\n",
    "            pass\n",
    "    for j in rating_tag :\n",
    "        try:\n",
    "            rating.append(j.text)\n",
    "        except:\n",
    "            pass\n",
    "    for k in rev_tag:\n",
    "        try:\n",
    "            rev.append(k.text.replace(\"\\n\",\" \"))\n",
    "        except:\n",
    "            pass\n",
    "    i=i+1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Full Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  The iPhone 11 of...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Excellent camera, good performance, no lag. Th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It’s been almost a month since I have been usi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Smooth like butter, camera like fantabulous, s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Summary                                        Full Review  \\\n",
       "1              Brilliant  The Best Phone for the Money  The iPhone 11 of...   \n",
       "2         Simply awesome  Really satisfied with the Product I received.....   \n",
       "3       Perfect product!  Amazing phone with great cameras and better ba...   \n",
       "4    Best in the market!  Great iPhone very snappy experience as apple k...   \n",
       "5      Worth every penny  Previously I was using one plus 3t it was a gr...   \n",
       "..                   ...                                                ...   \n",
       "96     Worth every penny  Best budget Iphone till date ❤️ go for it guys...   \n",
       "97    Highly recommended  It's my first time to use iOS phone and I am l...   \n",
       "98        Simply awesome  Excellent camera, good performance, no lag. Th...   \n",
       "99     Worth every penny  It’s been almost a month since I have been usi...   \n",
       "100    Worth every penny  Smooth like butter, camera like fantabulous, s...   \n",
       "\n",
       "    Rating  \n",
       "1        5  \n",
       "2        5  \n",
       "3        5  \n",
       "4        5  \n",
       "5        5  \n",
       "..     ...  \n",
       "96       5  \n",
       "97       5  \n",
       "98       5  \n",
       "99       5  \n",
       "100      5  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "iphoneDF = pd.DataFrame({\"Summary\":rev_sum[0:100],\"Full Review\":rev[0:100],\"Rating\":rating[0:100]})\n",
    "iphoneDF.reset_index(drop=True,inplace = True)\n",
    "iphoneDF.index+= 1\n",
    "iphoneDF.shape\n",
    "iphoneDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")  #initating webdriver and opening flipkart webpage\n",
    "url = 'https://www.flipkart.com' \n",
    "driver.get(url)\n",
    "Sneakerssearch = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input') #search bar code\n",
    "Sneakerssearch.send_keys(\"Sneakers\")  #sending sneaker key to searchbar\n",
    "search = driver.find_element_by_class_name('L0Z3Pu')\n",
    "search.click()  #clicking on click button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []  #creating empty list\n",
    "desc = []\n",
    "price = []\n",
    "disc = []\n",
    "brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")  #scraping brand,price,discount,description\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "for b in brand_tag:\n",
    "    brand.append(b.text)\n",
    "for d in desc_tag :\n",
    "    desc.append(d.text)\n",
    "for p in price_tag:\n",
    "    price.append(p.text)\n",
    "for c in disc_tag:\n",
    "    disc.append(c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "code for next button\n",
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('_1LKTO3')\n",
    "while(i<2):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    disc_tag = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    \n",
    "    for b in brand_tag:\n",
    "        try:\n",
    "            brand.append(b.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for d in desc_tag :\n",
    "        try:\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for p in price_tag:\n",
    "        try:\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            pass\n",
    "    for c in disc_tag:\n",
    "        try:\n",
    "            disc.append(c.text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    if 'inactive' in nextbtn.get_attribute('class'):\n",
    "        break;\n",
    "    \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T-ROCK</td>\n",
       "      <td>₹359</td>\n",
       "      <td>64% off</td>\n",
       "      <td>Synthetic Leather Casual Partywear Wedding Sne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>₹2,399</td>\n",
       "      <td>40% off</td>\n",
       "      <td>Puma Smash v2 SL one8 Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>₹425</td>\n",
       "      <td>78% off</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>₹247</td>\n",
       "      <td>75% off</td>\n",
       "      <td>Unique &amp; Perfect Collection Combo Pack of 02 S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>₹420</td>\n",
       "      <td>71% off</td>\n",
       "      <td>White Sneaker For Men Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>₹1,749</td>\n",
       "      <td>50% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>₹499</td>\n",
       "      <td>55% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>₹449</td>\n",
       "      <td>32% off</td>\n",
       "      <td>Comfortable &amp; Ultra Light Weight Sneaker Sneak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>₹2,639</td>\n",
       "      <td>25% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>CHamps</td>\n",
       "      <td>₹974</td>\n",
       "      <td>73% off</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand Name Price(₹) Discount  \\\n",
       "1                   T-ROCK     ₹359  64% off   \n",
       "2                     PUMA   ₹2,399  40% off   \n",
       "3                   Chevit     ₹425  78% off   \n",
       "4                 URBANBOX     ₹247  75% off   \n",
       "5                   Chevit     ₹420  71% off   \n",
       "..                     ...      ...      ...   \n",
       "96                    PUMA   ₹1,749  50% off   \n",
       "97            Robbie jones     ₹499  55% off   \n",
       "98            Robbie jones     ₹449  32% off   \n",
       "99   HRX by Hrithik Roshan   ₹2,639  25% off   \n",
       "100                 CHamps     ₹974  73% off   \n",
       "\n",
       "                                           Description  \n",
       "1    Synthetic Leather Casual Partywear Wedding Sne...  \n",
       "2               Puma Smash v2 SL one8 Sneakers For Men  \n",
       "3    Combo Pack of 4 Casual Sneakers With Sneakers ...  \n",
       "4    Unique & Perfect Collection Combo Pack of 02 S...  \n",
       "5               White Sneaker For Men Sneakers For Men  \n",
       "..                                                 ...  \n",
       "96                                    Sneakers For Men  \n",
       "97                                    Sneakers For Men  \n",
       "98   Comfortable & Ultra Light Weight Sneaker Sneak...  \n",
       "99                                    Sneakers For Men  \n",
       "100  Perfect & Affordable Combo Pack of 02 Pairs Sn...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating datafrme\n",
    "SneakersDF = pd.DataFrame({\"Brand Name\":brand[0:100],\"Price(₹)\":price[0:100],\"Discount\":disc[0:100],\"Description\":desc[0:100],})\n",
    "SneakersDF.reset_index(drop=True,inplace = True)\n",
    "SneakersDF.index+= 1\n",
    "SneakersDF.shape\n",
    "\n",
    "SneakersDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: Go to the link - https://www.myntra.com/shoes\n",
    "#### Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")  #initiating chrome driver\n",
    "url = 'https://www.myntra.com/shoes'  #opening webpage\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label\")\n",
    "colour_filter.click()  #color filter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_filter = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\")\n",
    "price_filter.click()  #price filter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []#creating empty lists to store desired data init\n",
    "desc = []\n",
    "price = []\n",
    "price2 = []\n",
    "# scraping brand.price,description\n",
    "brand_tag = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='product-price']//span[1]\")\n",
    "desc_tag = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "# next button code\n",
    "i=0\n",
    "nextbtn = driver.find_element_by_class_name('pagination-next')\n",
    "while(i<1):\n",
    "    try:\n",
    "        nextbtn.click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) #to allow the page to load completely before scraping.\n",
    "    brand_tag = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    price_tag = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']//span[1]\")\n",
    "    desc_tag = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "\n",
    "    \n",
    "    for b in brand_tag:\n",
    "        try:\n",
    "            brand.append(b.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for d in desc_tag :\n",
    "        try:\n",
    "            desc.append(d.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for p in price_tag:\n",
    "        try:\n",
    "            price.append(p.text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    if 'inactive' in nextbtn.get_attribute('class'):\n",
    "        break;\n",
    "    \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "price #has duplicate values\n",
    "while(\"\" in price) :\n",
    "    price.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 7799Rs. 12999',\n",
       " 'Rs. 7799',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 7599',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 11490',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7699Rs. 10999',\n",
       " 'Rs. 7699',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 13495',\n",
       " 'Rs. 8490',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 11699Rs. 12999',\n",
       " 'Rs. 11699',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 9995',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 8999Rs. 11999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 13499Rs. 17999',\n",
       " 'Rs. 13499',\n",
       " 'Rs. 9999']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 7799',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 10999',\n",
       " 'Rs. 7599',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 11490',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7699',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 13495',\n",
       " 'Rs. 8490',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 11699',\n",
       " 'Rs. 7499',\n",
       " 'Rs. 9995',\n",
       " 'Rs. 7999',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 9999',\n",
       " 'Rs. 7990',\n",
       " 'Rs. 11999',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 12999',\n",
       " 'Rs. 8990',\n",
       " 'Rs. 8999',\n",
       " 'Rs. 13499',\n",
       " 'Rs. 9999']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing duplicate values\n",
    "j = 0\n",
    "for c in price:\n",
    "    if len(c) > 12:\n",
    "        del price[j]\n",
    "    j += 1\n",
    "    \n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 7799</td>\n",
       "      <td>Women Magnify Nitro Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Rs. 7499</td>\n",
       "      <td>Women Charged Impulse Shft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Rs. 8999</td>\n",
       "      <td>Women Quilted Leather Pumps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MANGO</td>\n",
       "      <td>Rs. 7990</td>\n",
       "      <td>Women WovenDesign Sports Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Rs. 10999</td>\n",
       "      <td>Women Leather Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Rs. 7599</td>\n",
       "      <td>Women Textured Pumps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Onitsuka Tiger</td>\n",
       "      <td>Rs. 8999</td>\n",
       "      <td>Women Perforations Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Women Hybrid Leather Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Men Black Running Sports Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Rs. 12999</td>\n",
       "      <td>Men Wingtip Oxford Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Rs. 11999</td>\n",
       "      <td>Men GENERATION ZEROGRAND STITCHLITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Rs. 12999</td>\n",
       "      <td>Men Leather Mid-Top Flat Boots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Rs. 8999</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Rs. 7990</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Rs. 7990</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>Men Leather Slip-On Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Men Leather Derbys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Rs. 11490</td>\n",
       "      <td>Men Leather Formal Derbys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Rs. 8990</td>\n",
       "      <td>Men Solid Leather Formal Monks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Men Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Rs. 8990</td>\n",
       "      <td>Ustraa black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Rs. 7990</td>\n",
       "      <td>Solid Slip On Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Rs. 7990</td>\n",
       "      <td>Solid Leather Formal Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Rs. 11999</td>\n",
       "      <td>Men Leather Flat Boots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Rs. 8990</td>\n",
       "      <td>Men Formal Leather Slip-Ons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RARE RABBIT</td>\n",
       "      <td>Rs. 7699</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Rs. 8990</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Rs. 7990</td>\n",
       "      <td>Men Textured Formal Leather Oxfords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RARE RABBIT</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>Men Leather Flat Boots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Calvin Klein</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Men Solid Suede Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Rs. 8990</td>\n",
       "      <td>Men Textured Formal Leather Loafers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 13495</td>\n",
       "      <td>Women Air Zoom Vomero 16 Run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Rs. 8490</td>\n",
       "      <td>Men Black Leather Loafers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>Men Leather Formal Derbys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Rs. 11699</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pavers England</td>\n",
       "      <td>Rs. 7499</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 9995</td>\n",
       "      <td>Men AIR ZOOM PEGASUS 36 Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Men Court Jam Bounce Tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Rs. 7990</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pavers England</td>\n",
       "      <td>Rs. 8999</td>\n",
       "      <td>Men Textured Leather Formal Derbys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>GEL-Cumulus Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Rs. 7990</td>\n",
       "      <td>Formal Oxford Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Rs. 11999</td>\n",
       "      <td>Women Open Toe Flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Rs. 8999</td>\n",
       "      <td>Men X9000L3 Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Rs. 12999</td>\n",
       "      <td>Women Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Rs. 8990</td>\n",
       "      <td>Men Textured Leather Formal Slip-Ons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Rs. 8999</td>\n",
       "      <td>Women Solid Leather Ballerinas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Rs. 13499</td>\n",
       "      <td>Men Ultraboost X Lego Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>Men Black Running Shoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name   Price(₹)                           Description\n",
       "1             Puma   Rs. 7799             Women Magnify Nitro Shoes\n",
       "2     UNDER ARMOUR   Rs. 7499            Women Charged Impulse Shft\n",
       "3             Geox   Rs. 8999           Women Quilted Leather Pumps\n",
       "4            MANGO   Rs. 7990        Women WovenDesign Sports Shoes\n",
       "5        Cole Haan  Rs. 10999                Women Leather Sneakers\n",
       "6   Tommy Hilfiger   Rs. 7599                  Women Textured Pumps\n",
       "7   Onitsuka Tiger   Rs. 8999           Women Perforations Sneakers\n",
       "8   Tommy Hilfiger   Rs. 7999         Women Hybrid Leather Sneakers\n",
       "9            ASICS   Rs. 7999        Men Black Running Sports Shoes\n",
       "10       Cole Haan  Rs. 12999           Men Wingtip Oxford Sneakers\n",
       "11       Cole Haan  Rs. 11999   Men GENERATION ZEROGRAND STITCHLITE\n",
       "12            Geox  Rs. 12999        Men Leather Mid-Top Flat Boots\n",
       "13         Bugatti   Rs. 8999                     Men Walking Shoes\n",
       "14       J.FONTINI   Rs. 7990          Men Textured Leather Loafers\n",
       "15       J.FONTINI   Rs. 7990          Men Textured Leather Loafers\n",
       "16    Hush Puppies   Rs. 9999          Men Leather Slip-On Sneakers\n",
       "17           ASICS   Rs. 7999                     Men Running Shoes\n",
       "18    Hush Puppies   Rs. 7999                    Men Leather Derbys\n",
       "19            Geox  Rs. 11490             Men Leather Formal Derbys\n",
       "20           Ruosh   Rs. 8990        Men Solid Leather Formal Monks\n",
       "21         Bugatti   Rs. 7999                          Men Sneakers\n",
       "22        DAVINCHI   Rs. 8990                          Ustraa black\n",
       "23        DAVINCHI   Rs. 7990                   Solid Slip On Shoes\n",
       "24        DAVINCHI   Rs. 7990            Solid Leather Formal Shoes\n",
       "25            Geox  Rs. 11999                Men Leather Flat Boots\n",
       "26        DAVINCHI   Rs. 8990           Men Formal Leather Slip-Ons\n",
       "27     RARE RABBIT   Rs. 7699          Men Textured Leather Loafers\n",
       "28        DAVINCHI   Rs. 8990       Men Solid Leather Formal Derbys\n",
       "29        DAVINCHI   Rs. 7990   Men Textured Formal Leather Oxfords\n",
       "30     RARE RABBIT   Rs. 9999                Men Leather Flat Boots\n",
       "31    Calvin Klein   Rs. 7999              Men Solid Suede Sneakers\n",
       "32        DAVINCHI   Rs. 8990   Men Textured Formal Leather Loafers\n",
       "33            Nike  Rs. 13495          Women Air Zoom Vomero 16 Run\n",
       "34       J.FONTINI   Rs. 8490             Men Black Leather Loafers\n",
       "35            Geox   Rs. 9999             Men Leather Formal Derbys\n",
       "36  ROSSO BRUNELLO  Rs. 11699            Men Leather Formal Loafers\n",
       "37  Pavers England   Rs. 7499             Men Leather Driving Shoes\n",
       "38            Nike   Rs. 9995         Men AIR ZOOM PEGASUS 36 Shoes\n",
       "39          ADIDAS   Rs. 7999           Men Court Jam Bounce Tennis\n",
       "40        DAVINCHI   Rs. 7990       Men Solid Leather Formal Derbys\n",
       "41  Pavers England   Rs. 8999    Men Textured Leather Formal Derbys\n",
       "42           ASICS   Rs. 9999             GEL-Cumulus Running Shoes\n",
       "43       J.FONTINI   Rs. 7990                   Formal Oxford Shoes\n",
       "44       Cole Haan  Rs. 11999                  Women Open Toe Flats\n",
       "45          ADIDAS   Rs. 8999             Men X9000L3 Running Shoes\n",
       "46       Cole Haan  Rs. 12999                        Women Sneakers\n",
       "47        DAVINCHI   Rs. 8990  Men Textured Leather Formal Slip-Ons\n",
       "48            Geox   Rs. 8999        Women Solid Leather Ballerinas\n",
       "49          ADIDAS  Rs. 13499         Men Ultraboost X Lego Running\n",
       "50           ASICS   Rs. 9999               Men Black Running Shoes"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating datafreame\n",
    "MyntraShoesDF = pd.DataFrame({\"Brand Name\":brand[0:100],\"Price(₹)\":price[0:100],\"Description\":desc[0:100],})\n",
    "MyntraShoesDF.reset_index(drop=True,inplace = True)\n",
    "MyntraShoesDF.index+= 1\n",
    "\n",
    "\n",
    "MyntraShoesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/¶\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\") #initiating chrome driver and webpage\n",
    "url = 'https://www.amazon.in/' \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Laptopsearch = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "Laptopsearch.send_keys(\"Laptop\")  #search bar code and clicking on it\n",
    "search = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:   #applying filetr here\n",
    "    i7_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[5]/ul[1]/li[14]/span/a/span\")\n",
    "    i7_filter.click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:#applying filter here\n",
    "    i9_filter=driver.find_elements_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[5]/ul[1]/li[15]/span/a/span\")\n",
    "    i9_filter\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = [] #creating empty list\n",
    "price = []\n",
    "Rating = []\n",
    "Rating_tag = driver.find_elements_by_xpath(\"//span[@class='a-icon-alt']\")\n",
    "title_tag = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "price_tag = driver.find_elements_by_xpath(\"//div[@class='sg-col-inner']//span[@class='a-price-whole']\")\n",
    "\n",
    "for i in title_tag:\n",
    "    title.append(i.text)\n",
    "    \n",
    "for r in Rating_tag :\n",
    "    Rating.append(r.get_attribute(\"innerHTML\"))\n",
    "    \n",
    "for p in price_tag:\n",
    "    price.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "del title[8] #deleting element with no price attribute to prevent price mismatch in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.0 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '4.0 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '3.3 out of 5 stars',\n",
       " '4.0 out of 5 stars',\n",
       " '4.6 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '3.1 out of 5 stars',\n",
       " '4.5 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.6 out of 5 stars',\n",
       " '3.9 out of 5 stars',\n",
       " '4.9 out of 5 stars',\n",
       " '3.6 out of 5 stars',\n",
       " '3.0 out of 5 stars',\n",
       " '4.0 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '3.5 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '4.3 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '4 Stars &amp; Up',\n",
       " '3 Stars &amp; Up',\n",
       " '2 Stars &amp; Up',\n",
       " '1 Star &amp; Up']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>Price(₹)</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel i7 Core 13.3 inche...</td>\n",
       "      <td>92,990</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Pro QHD+ IPS Anti Glare Display In...</td>\n",
       "      <td>72,999</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...</td>\n",
       "      <td>1,03,390</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion Gaming(2021) 10th Gen Intel Core i...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>43,199</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>87,990</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14-inc...</td>\n",
       "      <td>56,790</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Laptop Name  Price(₹)  \\\n",
       "1   Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...    89,990   \n",
       "2   Fujitsu UH-X 11th Gen Intel i7 Core 13.3 inche...    92,990   \n",
       "3   Mi Notebook Pro QHD+ IPS Anti Glare Display In...    72,999   \n",
       "4   Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...  1,03,390   \n",
       "5   HP Pavilion Gaming(2021) 10th Gen Intel Core i...    89,990   \n",
       "6   HP Pavilion (2021) Intel 11th Gen Core i7 14 i...    84,990   \n",
       "7   Life Digital Laptop 15.6-inch (39.62 cms) (Int...    43,199   \n",
       "8   Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...    89,990   \n",
       "9   Mi Notebook Horizon Edition 14 Intel Core i7-1...    87,990   \n",
       "10  HP Pavilion x360 11th Gen Intel Core i7 14-inc...    56,790   \n",
       "\n",
       "                Rating  \n",
       "1   4.0 out of 5 stars  \n",
       "2   4.3 out of 5 stars  \n",
       "3   4.3 out of 5 stars  \n",
       "4   4.3 out of 5 stars  \n",
       "5   4.0 out of 5 stars  \n",
       "6   4.3 out of 5 stars  \n",
       "7   3.3 out of 5 stars  \n",
       "8   4.0 out of 5 stars  \n",
       "9   4.6 out of 5 stars  \n",
       "10  4.2 out of 5 stars  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "LaptopDF = pd.DataFrame({\"Laptop Name\":title[0:10],\"Price(₹)\":price[0:10],\"Rating\":Rating[0:10]})\n",
    "LaptopDF.reset_index(drop=True,inplace = True)\n",
    "LaptopDF.index+= 1\n",
    "LaptopDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\gavel\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\gavel\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#connecting to the webdriver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "# driver=webdriver.Chrome(r\"C:\\Users\\gavel\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ambitionbox.com/' #code to got on desired webpage\n",
    "driver.get(url)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"a1b7165c6affac728fd7031b69820cb5\", element=\"fc7c02e4-d662-4d66-b344-c267fa57c03c\")>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job=driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[6]\") #going to job page\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div/div/div/div/span/input\")\n",
    "search_bar\n",
    "search_bar.send_keys(\"Data Scientist\")  #search bar code and endering data scientist key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div/div/div/button/span\")\n",
    "click_.click()  #clicking on click button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"a1b7165c6affac728fd7031b69820cb5\", element=\"0c8fc933-1ae2-4150-8ef8-3805856b4e80\")>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]/i\")\n",
    "location  #location search bar code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]/i\")\n",
    "# b.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_loc=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "search_loc.send_keys(\"Noida\")  #selecting noida from drop down box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "noida=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\")\n",
    "noida.click()  #clciking on noida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ericsson India Global Services Pvt. Ltd.\\n · \\n4.2\\nbased on 3.9k Reviews',\n",
       " 'Ericsson India Global Services Pvt. Ltd.\\n4.2\\n(3.9k Reviews)',\n",
       " 'GENPACT India Private Limited\\n4.0\\n(11.8k Reviews)',\n",
       " 'GENPACT India Private Limited\\n4.0\\n(11.8k Reviews)',\n",
       " 'NTT Data Business Solutions Pvt Ltd\\n3.8\\n(2.9k Reviews)',\n",
       " 'GENPACT India Private Limited\\n4.0\\n(11.8k Reviews)',\n",
       " 'GI Group\\n4.0\\n(70 Reviews)',\n",
       " 'GI Group\\n4.0\\n(70 Reviews)',\n",
       " 'GI Group\\n4.0\\n(70 Reviews)',\n",
       " 'Steria India Ltd\\n4.1\\n(849 Reviews)',\n",
       " 'Zyoin\\n4.1\\n(64 Reviews)']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping company name\n",
    "company_name=driver.find_elements_by_xpath(\"//div[@class='company-info']\")\n",
    "company=[]\n",
    "for i in company_name:\n",
    "    company.append(i.text)\n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20hr ago',\n",
       " 'via naukri.com',\n",
       " '6d ago',\n",
       " 'via naukri.com',\n",
       " '6d ago',\n",
       " 'via naukri.com',\n",
       " '7d ago',\n",
       " 'via naukri.com',\n",
       " '8d ago',\n",
       " 'via naukri.com']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping number of days ago job posted\n",
    "days=driver.find_elements_by_xpath(\"//span[@class='body-small-l']\")\n",
    "days_ago=[]\n",
    "for i in days:\n",
    "    days_ago.append(i.text)\n",
    "days_ago[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.2', '4.0', '4.0', '3.8', '4.0', '4.0', '4.0', '4.0', '4.1', '4.1']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping rating\n",
    "rating=driver.find_elements_by_xpath(\"//span[@class='body-small']\")\n",
    "Rating=[]\n",
    "for i in rating:\n",
    "    Rating.append(i.text)\n",
    "Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Title</th>\n",
       "      <th>Days_ago</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.\\n · \\...</td>\n",
       "      <td>20hr ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.\\n4.2\\...</td>\n",
       "      <td>via naukri.com</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENPACT India Private Limited\\n4.0\\n(11.8k Rev...</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENPACT India Private Limited\\n4.0\\n(11.8k Rev...</td>\n",
       "      <td>via naukri.com</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NTT Data Business Solutions Pvt Ltd\\n3.8\\n(2.9...</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GENPACT India Private Limited\\n4.0\\n(11.8k Rev...</td>\n",
       "      <td>via naukri.com</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GI Group\\n4.0\\n(70 Reviews)</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GI Group\\n4.0\\n(70 Reviews)</td>\n",
       "      <td>via naukri.com</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GI Group\\n4.0\\n(70 Reviews)</td>\n",
       "      <td>8d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Steria India Ltd\\n4.1\\n(849 Reviews)</td>\n",
       "      <td>via naukri.com</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company_Title        Days_ago Rating\n",
       "1   Ericsson India Global Services Pvt. Ltd.\\n · \\...        20hr ago    4.2\n",
       "2   Ericsson India Global Services Pvt. Ltd.\\n4.2\\...  via naukri.com    4.0\n",
       "3   GENPACT India Private Limited\\n4.0\\n(11.8k Rev...          6d ago    4.0\n",
       "4   GENPACT India Private Limited\\n4.0\\n(11.8k Rev...  via naukri.com    3.8\n",
       "5   NTT Data Business Solutions Pvt Ltd\\n3.8\\n(2.9...          6d ago    4.0\n",
       "6   GENPACT India Private Limited\\n4.0\\n(11.8k Rev...  via naukri.com    4.0\n",
       "7                         GI Group\\n4.0\\n(70 Reviews)          7d ago    4.0\n",
       "8                         GI Group\\n4.0\\n(70 Reviews)  via naukri.com    4.0\n",
       "9                         GI Group\\n4.0\\n(70 Reviews)          8d ago    4.1\n",
       "10               Steria India Ltd\\n4.1\\n(849 Reviews)  via naukri.com    4.1"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping dataframe\n",
    "DF = pd.DataFrame({\"Company_Title\":company[0:10],\"Days_ago\":days_ago[0:10],\"Rating\":Rating[0:10]})\n",
    "DF.reset_index(drop=True,inplace = True)\n",
    "DF.index+= 1   #this will start your indexing with 1 not with 0\n",
    "\n",
    "DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary. The above task will be, done as shown in the below steps:\n",
    "\n",
    "First get the webpage https://www.ambitionbox.com/\n",
    "Click on the salaries option as shown in the image. ASSIGNMENT 2\n",
    "After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”. You have to scrape the data ticked in the above image.\n",
    "Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "Store the data i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the webdriver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "# driver=webdriver.Chrome(r\"C:\\Users\\gavel\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ambitionbox.com/' \n",
    "driver.get(url)  #opening the desired webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary=driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[4]\")\n",
    "salary.click()   #code for search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_search=driver.find_element_by_id(\"jobProfileSearchbox\")\n",
    "job_search.send_keys(\"Data Scientist\")  #getting job pages with this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element_by_xpath(\"//span[@class='ctas-btn-medium']\")\n",
    "button.click()  #click on the click button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft Corporation\\nbased on 217 salaries',\n",
       " 'Goldman Sachs\\nbased on 10 salaries',\n",
       " 'Flipkart\\nbased on 52 salaries',\n",
       " 'Amazon\\nbased on 77 salaries',\n",
       " 'Arcesium\\nbased on 34 salaries',\n",
       " 'Walmart\\nbased on 77 salaries',\n",
       " 'Servicenow Software Development India\\nbased on 26 salaries',\n",
       " 'ServiceNow\\nbased on 16 salaries',\n",
       " 'PayPal\\nbased on 12 salaries',\n",
       " 'Citrix\\nbased on 10 salaries']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping company name\n",
    "company_name=driver.find_elements_by_xpath(\"//div[@class='name']\")\n",
    "company=[]\n",
    "for i in company_name:\n",
    "    company.append(i.text)\n",
    "company    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['based on 217 salaries',\n",
       " 'based on 10 salaries',\n",
       " 'based on 52 salaries',\n",
       " 'based on 77 salaries',\n",
       " 'based on 34 salaries',\n",
       " 'based on 77 salaries',\n",
       " 'based on 26 salaries',\n",
       " 'based on 16 salaries',\n",
       " 'based on 12 salaries',\n",
       " 'based on 10 salaries']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping based on salary's number here\n",
    "salary=driver.find_elements_by_xpath(\"//div[@class='name']/span\")\n",
    "salary_=[]\n",
    "for i in salary:\n",
    "    salary_.append(i.text)\n",
    "salary_\n",
    "\n",
    "# /html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div[1]/div[1]/div/div/div[1]/span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 22.4L',\n",
       " '₹ 21.2L',\n",
       " '₹ 20.6L',\n",
       " '₹ 19.3L',\n",
       " '₹ 18.3L',\n",
       " '₹ 17.8L',\n",
       " '₹ 17.8L',\n",
       " '₹ 17.8L',\n",
       " '₹ 17.6L',\n",
       " '₹ 17.3L']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg=driver.find_elements_by_xpath(\"//p[@class='averageCtc']\")\n",
    "avg_salary=[]\n",
    "for i in avg:\n",
    "    avg_salary.append(i.text)\n",
    "avg_salary  #here we get avg salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['₹ 12.0L', '₹ 45.0L', '₹ 16.0L', '₹ 30.0L', '₹ 7.0L', '₹ 30.0L', '₹ 8.0L', '₹ 40.0L', '₹ 12.0L', '₹ 30.0L', '₹ 10.0L', '₹ 32.0L', '₹ 12.0L', '₹ 24.5L', '₹ 11.2L', '₹ 23.0L', '₹ 12.0L', '₹ 23.0L', '₹ 12.0L', '₹ 22.0L']\n"
     ]
    }
   ],
   "source": [
    "min=driver.find_elements_by_xpath(\"//div[@class='value body-medium']\")\n",
    "min_salary=[]    #here we get max and min both value of salary need to seperate it\n",
    "for i in min:\n",
    "    min_salary.append(i.text)\n",
    "print(min_salary)\n",
    "# len(min_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 12.0L',\n",
       " '₹ 16.0L',\n",
       " '₹ 7.0L',\n",
       " '₹ 8.0L',\n",
       " '₹ 12.0L',\n",
       " '₹ 10.0L',\n",
       " '₹ 12.0L',\n",
       " '₹ 11.2L',\n",
       " '₹ 12.0L',\n",
       " '₹ 12.0L']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[]\n",
    "for i in range(0,len(min_salary),2):\n",
    "    a.append(min_salary[i])\n",
    "a #storing min value of salary in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 45.0L',\n",
       " '₹ 30.0L',\n",
       " '₹ 30.0L',\n",
       " '₹ 40.0L',\n",
       " '₹ 30.0L',\n",
       " '₹ 32.0L',\n",
       " '₹ 24.5L',\n",
       " '₹ 23.0L',\n",
       " '₹ 23.0L',\n",
       " '₹ 22.0L']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=[]\n",
    "for i in range(1,len(min_salary),2):\n",
    "    b.append(min_salary[i])\n",
    "b  #storing max value of salary in b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Title</th>\n",
       "      <th>based_salary</th>\n",
       "      <th>Avg_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>min_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation\\nbased on 217 salaries</td>\n",
       "      <td>based on 217 salaries</td>\n",
       "      <td>₹ 22.4L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goldman Sachs\\nbased on 10 salaries</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 21.2L</td>\n",
       "      <td>₹ 30.0L</td>\n",
       "      <td>₹ 16.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flipkart\\nbased on 52 salaries</td>\n",
       "      <td>based on 52 salaries</td>\n",
       "      <td>₹ 20.6L</td>\n",
       "      <td>₹ 30.0L</td>\n",
       "      <td>₹ 7.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon\\nbased on 77 salaries</td>\n",
       "      <td>based on 77 salaries</td>\n",
       "      <td>₹ 19.3L</td>\n",
       "      <td>₹ 40.0L</td>\n",
       "      <td>₹ 8.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arcesium\\nbased on 34 salaries</td>\n",
       "      <td>based on 34 salaries</td>\n",
       "      <td>₹ 18.3L</td>\n",
       "      <td>₹ 30.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Walmart\\nbased on 77 salaries</td>\n",
       "      <td>based on 77 salaries</td>\n",
       "      <td>₹ 17.8L</td>\n",
       "      <td>₹ 32.0L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Servicenow Software Development India\\nbased o...</td>\n",
       "      <td>based on 26 salaries</td>\n",
       "      <td>₹ 17.8L</td>\n",
       "      <td>₹ 24.5L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ServiceNow\\nbased on 16 salaries</td>\n",
       "      <td>based on 16 salaries</td>\n",
       "      <td>₹ 17.8L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>₹ 11.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PayPal\\nbased on 12 salaries</td>\n",
       "      <td>based on 12 salaries</td>\n",
       "      <td>₹ 17.6L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Citrix\\nbased on 10 salaries</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 17.3L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company_Title           based_salary  \\\n",
       "1        Microsoft Corporation\\nbased on 217 salaries  based on 217 salaries   \n",
       "2                 Goldman Sachs\\nbased on 10 salaries   based on 10 salaries   \n",
       "3                      Flipkart\\nbased on 52 salaries   based on 52 salaries   \n",
       "4                        Amazon\\nbased on 77 salaries   based on 77 salaries   \n",
       "5                      Arcesium\\nbased on 34 salaries   based on 34 salaries   \n",
       "6                       Walmart\\nbased on 77 salaries   based on 77 salaries   \n",
       "7   Servicenow Software Development India\\nbased o...   based on 26 salaries   \n",
       "8                    ServiceNow\\nbased on 16 salaries   based on 16 salaries   \n",
       "9                        PayPal\\nbased on 12 salaries   based on 12 salaries   \n",
       "10                       Citrix\\nbased on 10 salaries   based on 10 salaries   \n",
       "\n",
       "   Avg_salary max_salary min_salary  \n",
       "1     ₹ 22.4L    ₹ 45.0L    ₹ 12.0L  \n",
       "2     ₹ 21.2L    ₹ 30.0L    ₹ 16.0L  \n",
       "3     ₹ 20.6L    ₹ 30.0L     ₹ 7.0L  \n",
       "4     ₹ 19.3L    ₹ 40.0L     ₹ 8.0L  \n",
       "5     ₹ 18.3L    ₹ 30.0L    ₹ 12.0L  \n",
       "6     ₹ 17.8L    ₹ 32.0L    ₹ 10.0L  \n",
       "7     ₹ 17.8L    ₹ 24.5L    ₹ 12.0L  \n",
       "8     ₹ 17.8L    ₹ 23.0L    ₹ 11.2L  \n",
       "9     ₹ 17.6L    ₹ 23.0L    ₹ 12.0L  \n",
       "10    ₹ 17.3L    ₹ 22.0L    ₹ 12.0L  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "DF = pd.DataFrame({\"Company_Title\":company[0:10],\"based_salary\":salary_[0:10],\"Avg_salary\":avg_salary[0:10],\"max_salary\":b[0:10],\"min_salary\":a[0:10]})\n",
    "DF.reset_index(drop=True,inplace = True)\n",
    "DF.index+= 1   #this will start your indexing with 1 not with 0\n",
    "\n",
    "DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
